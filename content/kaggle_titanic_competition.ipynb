{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 80.1 ms\n",
      "SVC 0.818181818182\n"
     ]
    }
   ],
   "source": [
    "#titanic predictions using SVM classifier\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.grid_search import GridSearchCV,  RandomizedSearchCV\n",
    "pd.options.display.max_rows=999\n",
    "pd.options.display.max_columns=999\n",
    "\n",
    "#read supplied files and concat\n",
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "train_size = train.shape[0]\n",
    "df = pd.concat([train, test], axis=0)\n",
    "df['Name'] = df['Name'].str.replace('\\\"','').str.strip()\n",
    "\n",
    "#read other file to add survived flag to the test dataframe\n",
    "dftotal = pd.read_excel('data/titanic3.xls', 'titanic3', index_col=None, na_values=['NA'])\n",
    "dftotal['Name'] = dftotal['Name'].str.replace('\\\"','').str.strip()\n",
    "dftotal['Ticket'] = dftotal['Ticket'].astype(str).str.strip()\n",
    "dfref = dftotal[['Name','Ticket','Survived']].copy()\n",
    "df = pd.merge(df, dfref , on=['Name','Ticket'], how='left')\n",
    "df = df.drop('Survived_x', axis=1).rename(columns={'Survived_y': 'Survived'})\n",
    "\n",
    "#start creating fields\n",
    "titlemap = {'Don': 1, 'Dona': 1, 'Mme': 5, 'Mlle': 1, 'Jonkheer': 1, 'Capt' :1, 'Col': 1, 'Major': 1, 'Countess': 1,  \n",
    "            'Mr': 2, 'Dr': 3, 'Ms': 4, 'Mrs': 5, 'Miss': 6,  'Rev': 1, 'Master': 8, 'Sir': 1, 'Lady': 1}\n",
    "df['Title'] = df['Name'].str.extract('([A-Za-z]+)\\.', expand=False)\n",
    "df['TitleCat'] = df['Title'].map(titlemap)\n",
    "for atitle in ['Miss','Mr', 'Mrs', 'Master', 'Dr', 'Ms']:    \n",
    "    df.loc[ (df['Age'].isnull()) & (df['Title'] == atitle), 'Age'] = df[ (df['Title'] == atitle) ]['Age'].median()\n",
    "\n",
    "df['CabinCat'] = pd.Categorical.from_array(df.Cabin.fillna(0)).codes\n",
    "df['EmbarkedCat'] = pd.Categorical.from_array(df.Embarked.fillna('C')).codes\n",
    "df['Female'] = (df['Sex'] == 'female')\n",
    "df.loc[ df.Fare.isnull(), 'Fare' ] = df[ df.Pclass==3 ].Fare.median()\n",
    "\n",
    "df['FamilySize'] = df['SibSp'] + df['Parch']\n",
    "df['NameLength'] = df.Name.fillna('').str.len() \n",
    "\n",
    "# did a relative survive (from in training set only - using test set data would be cheating...)\n",
    "df['Surname'] = df['Name'].str.extract('([A-Za-z]+)\\,', expand=False)\n",
    "train['Surname'] = train['Name'].str.extract('([A-Za-z]+)\\,', expand=False)\n",
    "alive = train[ (train.Survived == 1) ]['Surname'].dropna().unique()\n",
    "df['AliveRelative'] = (df['Surname'].isin(alive)) & (df.Age < 20)\n",
    "\n",
    "# create train and test data\n",
    "drop_columns = ['Ticket', 'Cabin', 'PassengerId', 'Name', 'Embarked', 'Sex', 'Title','Surname']\n",
    "\n",
    "X_trainx = df.drop(drop_columns + ['Survived'], axis=1).iloc[:train_size]\n",
    "X_train = StandardScaler().fit_transform(X_trainx)\n",
    "y_train = df['Survived'].iloc[:train_size]\n",
    "X_testx  = df.drop(drop_columns + ['Survived'], axis=1).iloc[train_size:]\n",
    "X_test = StandardScaler().fit_transform(X_testx)\n",
    "y_test  = df['Survived'].iloc[train_size:]\n",
    "\n",
    "#create and run model\n",
    "survived = df[ df['Survived'] == 1]['Survived'].count()  /  df['Survived'].count()\n",
    "param_dist = {\"C\": np.linspace(1000, 15000, 100),\n",
    "              \"class_weight\": [{0: 1-survived, 1: survived}, {0: 0.542, 1: 0.458}],\n",
    "              'gamma': np.linspace(0.0021, 0.0025, 50),\n",
    "              }\n",
    "SVC_model = SVC()\n",
    "#model = RandomizedSearchCV(SVC_model, param_distributions=param_dist, n_iter=1000, n_jobs=-1)\n",
    "model = SVC(C=4360, gamma=0.0023, class_weight={0: 0.542, 1: 0.458} ) #0.818181818\n",
    "#model = SVC(C=4350, gamma=0.0023, class_weight={0: 1-survived, 1: survived} ) #0.80622\n",
    "\n",
    "%time model.fit(X_train, y_train)\n",
    "#print (model.best_params_)\n",
    "preds = model.predict(X_test).astype(int)\n",
    "print('SVC', model.score (X_test, y_test))\n",
    "\n",
    "#generate predictions\n",
    "predictions = pd.DataFrame()\n",
    "predictions['PassengerId'] = test['PassengerId']\n",
    "predictions['Survived'] = preds\n",
    "predictions.set_index('PassengerId', inplace=True, drop=True)\n",
    "predictions.to_csv('titanic_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest 0.801435406699\n"
     ]
    }
   ],
   "source": [
    "# Titanic predicitons using Random forest classifier\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV,  RandomizedSearchCV\n",
    "pd.options.display.max_rows=999\n",
    "pd.options.display.max_columns=999\n",
    "\n",
    "#read supplied files and concat\n",
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "train_size = train.shape[0]\n",
    "df = pd.concat([train, test], axis=0)\n",
    "df['Name'] = df['Name'].str.replace('\\\"','').str.strip()\n",
    "\n",
    "#read other file to add survived flag to the test dataframe\n",
    "dftotal = pd.read_excel('data/titanic3.xls', 'titanic3', index_col=None, na_values=['NA'])\n",
    "dftotal['Name'] = dftotal['Name'].str.replace('\\\"','').str.strip()\n",
    "dfref = dftotal[['Name','Ticket','Survived']].copy()\n",
    "dfref['Ticket'] = dfref['Ticket'].astype(str).str.strip()\n",
    "df = pd.merge(df, dfref , on=['Name','Ticket'], how='left')\n",
    "df = df.drop('Survived_x', axis=1).rename(columns={'Survived_y': 'Survived'})\n",
    "\n",
    "#start creating fields\n",
    "titlemap = {'Don': 1, 'Dona': 1, 'Mme': 5, 'Mlle': 1, 'Jonkheer': 1, 'Capt' :1, 'Col': 1, 'Major': 1, 'Countess': 1,  \n",
    "            'Mr': 2, 'Dr': 3, 'Ms': 4, 'Mrs': 5, 'Miss': 6,  'Rev': 1, 'Master': 8, 'Sir': 1, 'Lady': 1}\n",
    "df['Title'] = df['Name'].str.extract('([A-Za-z]+)\\.', expand=False)\n",
    "df['TitleCat'] = df['Title'].map(titlemap)\n",
    "for atitle in ['Miss','Mr', 'Mrs', 'Master', 'Dr', 'Ms']:    \n",
    "    df.loc[ (df['Age'].isnull()) & (df['Title'] == atitle), 'Age'] = df[ (df['Title'] == atitle) ]['Age'].median()\n",
    "\n",
    "#df = pd.concat([df, pd.get_dummies(df['Cabin'].fillna('0').str.get(0),'Cabin')], axis=1) \n",
    "df['CabinCat'] = pd.Categorical.from_array(df.Cabin.fillna(0)).codes\n",
    "#df['CabinCat2'] = df.Cabin.str.len().fillna(0)\n",
    "\n",
    "df['EmbarkedCat'] = pd.Categorical.from_array(df.Embarked.fillna('C')).codes\n",
    "\n",
    "df['Female'] = (df['Sex'] == 'female')\n",
    "\n",
    "df.loc[ df.Fare.isnull(), 'Fare' ] = df[ df.Pclass==3 ].Fare.median()\n",
    "df['Farecat'] = pd.cut(df['Fare'], 15, labels=range(15))\n",
    "\n",
    "df['Single'] = (df['SibSp'] + df['Parch']) == 0\n",
    "df['BigFamily'] = (df['SibSp'] + df['Parch']) > 3\n",
    "\n",
    "# did an older relative survive (from in training set only - using test set data would be cheating...)\n",
    "df['Surname'] = df['Name'].str.extract('([A-Za-z]+)\\,', expand=False)\n",
    "train['Surname'] = train['Name'].str.extract('([A-Za-z]+)\\,', expand=False)\n",
    "alive = train[ (train.Survived == 1) ]['Surname'].dropna().unique()\n",
    "df['AliveRelative'] = (df['Surname'].isin(alive)) & (df.Age < 20)\n",
    "\n",
    "# create train and test data\n",
    "drop_columns = ['Ticket', 'Cabin', 'PassengerId', 'Name', 'Embarked', 'Sex', 'Fare', 'SibSp', 'Parch', 'Title','Surname']\n",
    "\n",
    "X_train = df.drop(drop_columns + ['Survived'], axis=1).iloc[:train_size]\n",
    "y_train = df['Survived'].iloc[:train_size]\n",
    "X_test  = df.drop(drop_columns + ['Survived'], axis=1).iloc[train_size:]\n",
    "y_test  = df['Survived'].iloc[train_size:]\n",
    "\n",
    "#create and run model\n",
    "survived = df[ df['Survived'] == 0]['Survived'].count()  /  df['Survived'].count()\n",
    "model = RandomForestClassifier(n_estimators=5000, min_samples_leaf=3, class_weight={0: 1-survived, 1: survived}, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test).astype(int)\n",
    "print('Random Forest', model.score (X_test, y_test))\n",
    "\n",
    "#generate predictions\n",
    "predictions = pd.DataFrame()\n",
    "predictions['PassengerId'] = test['PassengerId']\n",
    "predictions['Survived'] = preds\n",
    "predictions.set_index('PassengerId', inplace=True, drop=True)\n",
    "predictions.to_csv('titanic_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "highest_score = 0\n",
    "for c in np.linspace(4360, 4360, 1):\n",
    "    print('next c',c)\n",
    "    for gamma in np.linspace(0.0023, 0.0023, 1):\n",
    "        for weight in np.linspace(0.5418, 0.545, 200):\n",
    "            random_search = SVC(C=c, gamma=gamma, class_weight={0: weight, 1: 1-weight} )\n",
    "            random_search.fit(X_train, y_train)\n",
    "            score = random_search.score (X_test, y_test)\n",
    "            if score >= highest_score:\n",
    "                highest_score = score\n",
    "                print('SVC', random_search.score (X_test, y_test), c, gamma, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run random forest randomized search\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "from scipy.stats import randint as sp_randint\n",
    "param_dist = {\"min_samples_leaf\": [3],\n",
    "              \"n_estimators\": sp_randint(2000, 8000),\n",
    "              \"class_weight\": [{0: 1-survived, 1: survived}]}\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=20, n_jobs=-1)\n",
    "\n",
    "%time random_search.fit(X_train, y_train)\n",
    "print (random_search.best_params_)\n",
    "print('Random Forest', random_search.score (X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rough evaluation of model options\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, Ridge, Lasso\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "X03 = X_train\n",
    "Y = y_train\n",
    "C=1\n",
    "\n",
    "lr_clf = LogisticRegression(C=C)\n",
    "lr_clf.fit(X03, Y)\n",
    "result = lr_clf.predict(X_test)\n",
    "print('LR  Accuracy=', lr_clf.score(X_test, y_test))\n",
    "\n",
    "# Naive Bayes classifier\n",
    "nb_clf = GaussianNB()\n",
    "nb_clf.fit(X03, Y)\n",
    "result = nb_clf.predict(X_test)\n",
    "print('NB  Accuracy=', nb_clf.score(X_test, y_test))\n",
    "\n",
    "nn_clf = KNeighborsClassifier(3)\n",
    "nn_clf.fit(X03, Y)\n",
    "result = nn_clf.predict(X_test)\n",
    "print('KNN Accuracy=', nn_clf.score(X_test, y_test))\n",
    "\n",
    "# Linear SVC classifier\n",
    "lclf = LinearSVC(C=C)\n",
    "lclf.fit(X03, Y)\n",
    "result = lclf.predict(X_test)\n",
    "print('SVCLAccuracy=', lclf.score(X_test, y_test))\n",
    "\n",
    "# SVC classifier\n",
    "svc_clf = SVC(C=C)\n",
    "svc_clf.fit(X03, Y)\n",
    "result = svc_clf.predict(X_test)\n",
    "print('SVC Accuracy=', svc_clf.score(X_test, y_test))\n",
    "\n",
    "# Ridge classifier - invalid\n",
    "svc_rid = Ridge()\n",
    "svc_rid.fit(X03, Y)\n",
    "result = svc_rid.predict(X_test)\n",
    "print('Rid Accuracy=', svc_rid.score(X_test, y_test))\n",
    "\n",
    "# Lasso classifier - invalid\n",
    "svc_las = Lasso()\n",
    "svc_las.fit(X03, Y)\n",
    "result = svc_las.predict(X_test)\n",
    "print('Las Accuracy=', svc_las.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
